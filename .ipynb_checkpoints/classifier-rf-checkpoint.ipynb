{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from copy import copy\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e428208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Users/coimbravieira/Graphviz/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b28a04-f59e-4867-973e-96201120dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dim_fig(sizes=(16,20,20)):\n",
    "    SMALL_SIZE = sizes[0]\n",
    "    MEDIUM_SIZE = sizes[1]\n",
    "    BIGGER_SIZE = sizes[2]\n",
    "    \n",
    "    plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=MEDIUM_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ac2e6a-c773-4ee7-b689-6c6d7fb8d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dim_fig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f3b4b-c053-46f7-b332-cd9c0577762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cdf(df_stats, cols=[], color=None, xlab=\"Number of videos watched\", ylab=\"Proportion of users\", note=\"\"):\n",
    "       \n",
    "    df_stats[cols].plot.hist(figsize=(7,5), cumulative=True, density=1, bins=100, histtype='step', lw=4, alpha=0.6, color=color)\n",
    "\n",
    "    plt.legend(loc=(0.4,0.05))\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.savefig(f\"figs/cdf-{xlab}-{note}.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8992b648-a1e9-4f3f-8ec0-5f5a560c5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(df_stats, cols=[], color=None, percentage=False, xlab=\"Number of videos watched\", ylab=\"Proportion of users\", k=None, bar=\"v\", stacked=True, figsize=(10,20), note=\"\"):\n",
    "    \n",
    "    df_stats = df_stats[cols]\n",
    "    \n",
    "    if k:\n",
    "        df_stats = df_stats[:k]\n",
    "    \n",
    "    if bar == \"h\":\n",
    "        if len(cols) == 1:\n",
    "            df_stats.plot.barh(figsize=figsize, stacked=stacked, legend=False)\n",
    "        else:\n",
    "            df_stats.plot.barh(figsize=figsize, stacked=stacked)\n",
    "    else:\n",
    "        if len(cols) == 1:\n",
    "            df_stats.plot.bar(figsize=(figsize[1],figsize[0]), stacked=stacked, legend=False)\n",
    "        else:\n",
    "            df_stats.plot.bar(figsize=(figsize[1],figsize[0]), stacked=stacked)\n",
    "\n",
    "    #plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "\n",
    "    if percentage:\n",
    "        plt.gca().set_yticklabels([f'{x/100:.0%}' for x in plt.gca().get_yticks()]) \n",
    "\n",
    "    ylab = ylab.replace(\"\\n\",\"\")\n",
    "    plt.savefig(f\"figs/bar-{ylab}-{note}.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e2a7a-061b-469d-8433-5549c7deccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_count_perc (df_all, col='percentage_watched', title='Histogram of the Percentage of Video Watched'):\n",
    "    # Plot settings\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "    \n",
    "    # Plot histogram with counts\n",
    "    counts, bins, patches = ax1.hist(df_all[col], bins=100, alpha=0.9, color='purple', label=False)\n",
    "    ax1.set_xlabel('Percentage of the video watched')\n",
    "    ax1.set_ylabel('Count')\n",
    "    \n",
    "    # Create secondary y-axis for percentage\n",
    "    ax2 = ax1.twinx()\n",
    "    total = counts.sum()\n",
    "    percentages = counts / total * 100\n",
    "    ax2.plot(bins[:-1], percentages, 'w-', linewidth=0.00001, label=False)\n",
    "    ax2.set_ylabel('Percentage (%)')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figs/hist_{col}.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c364ea38-4e08-4857-9052-09e97b51cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_model (df_all_rf):\n",
    "    X2 = df_all_rf[\"Video ID playlist\"]\n",
    "    y2 = df_all_rf[\"watched_until_end\"]\n",
    "    \n",
    "    _, _, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "    \n",
    "    p0 = y2_train.value_counts(normalize=True)[0]\n",
    "    p1 = y2_train.value_counts(normalize=True)[1]\n",
    "    # Generate predictions with the best model\n",
    "    random.seed(42)\n",
    "    y2_pred = pd.Series([0 if random.random() <= p0 else 1 for i in y2_test])\n",
    "    \n",
    "    accuracy2 = accuracy_score(y2_test, y2_pred)\n",
    "    precision2 = precision_score(y2_test, y2_pred, average=\"macro\")\n",
    "    recall2 = recall_score(y2_test, y2_pred, average=\"macro\")\n",
    "    F12 = f1_score(y2_test, y2_pred, average=\"macro\")\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy2)\n",
    "    print(\"Precision:\", precision2)\n",
    "    print(\"Recall:\", recall2)\n",
    "    print(\"F1:\", F12)\n",
    "    \n",
    "    # Create the confusion matrix\n",
    "    cm2 = confusion_matrix(y2_test, y2_pred)\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm2).plot(cmap=plt.cm.Oranges)\n",
    "    os.makedirs(\"figs/classification\", exist_ok=True)\n",
    "    plt.savefig(\"figs/classification/cm-random.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e425255a-50da-41a7-b410-7eb415017a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_by_mode(df, target_col=\"watched_until_end\"):\n",
    "    # Get the columns to group by (all except the target column)\n",
    "    group_cols = [col for col in df.columns if col != target_col]\n",
    "    \n",
    "    # Group by those columns and aggregate the target column using mode\n",
    "    df_dedup = (\n",
    "        df.groupby(group_cols, as_index=False)[target_col]\n",
    "          .agg(lambda x: x.mode().iloc[0])  # take the most frequent value\n",
    "    )\n",
    "    \n",
    "    return df_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8238d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract prefix from feature name\n",
    "def get_prefix(name):\n",
    "    return name.split('_')[0]\n",
    "\n",
    "def randomforest_tiktok(X2_train, X2_test, y2_train, y2_test, shap_set=None, note=None):\n",
    "    # --- Save original feature names ---\n",
    "    feature_names = X2_train.columns\n",
    "\n",
    "    # --- Save original class names ---\n",
    "    class_names = {0:\"< 100%\", 1:\"100%\"}\n",
    "\n",
    "    # --- Standardize the Data ---\n",
    "    sc = StandardScaler()\n",
    "    X2_train_scaled = sc.fit_transform(X2_train)\n",
    "    X2_test_scaled = sc.transform(X2_test)\n",
    "\n",
    "    # --- Re-wrap scaled arrays as DataFrames to preserve column names ---\n",
    "    X2_train_scaled_df = pd.DataFrame(X2_train_scaled, columns=feature_names)\n",
    "    X2_test_scaled_df = pd.DataFrame(X2_test_scaled, columns=feature_names)\n",
    "\n",
    "    print(\"Train size:\", X2_train_scaled_df.shape)\n",
    "    print(\"Test size:\", X2_test_scaled_df.shape)\n",
    "    \n",
    "    # --- Random Search Parameters ---\n",
    "    param_dist = {\n",
    "        \"max_depth\": range(1, 100),\n",
    "        \"min_samples_leaf\": range(2, 20),\n",
    "        \"n_estimators\": range(10, 100, 10)\n",
    "    }\n",
    "\n",
    "    rf = RandomForestClassifier(class_weight = \"balanced\", random_state=42)\n",
    "\n",
    "    rand_search = RandomizedSearchCV(\n",
    "        rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10,\n",
    "        cv=5,\n",
    "        random_state=42,\n",
    "        refit=True\n",
    "    )\n",
    "\n",
    "    # --- Fit Model ---\n",
    "    rand_search.fit(X2_train_scaled_df, y2_train)\n",
    "    y2_pred = rand_search.predict(X2_test_scaled_df)\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    cm = confusion_matrix(y2_test, y2_pred)\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap=plt.cm.Oranges)\n",
    "    os.makedirs(\"figs/classification\", exist_ok=True)\n",
    "    plt.savefig(f\"figs/classification/cm-{note}.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = accuracy_score(y2_test, y2_pred)\n",
    "    precision = precision_score(y2_test, y2_pred, average=\"macro\")\n",
    "    recall = recall_score(y2_test, y2_pred, average=\"macro\")\n",
    "    f1 = f1_score(y2_test, y2_pred, average=\"macro\")\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1:\", f1)\n",
    "\n",
    "    # Compute AUC-ROC\n",
    "    y2_scores = rand_search.predict_proba(X2_test_scaled_df)[:, 1]\n",
    "    auc = roc_auc_score(y2_test, y2_scores)\n",
    "    print(f\"AUC-ROC: {auc:.3f}\")\n",
    "    \n",
    "    # Compute ROC curve points\n",
    "    fpr, tpr, thresholds = roc_curve(y2_test, y2_scores)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {auc:.3f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # diagonal line\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Tune threshold to maximize F1 score\n",
    "    best_f1 = 0\n",
    "    best_thresh = 0.5\n",
    "    for thresh in np.linspace(0, 1, 101):\n",
    "        y_pred_thresh = (y2_scores >= thresh).astype(int)\n",
    "        f1 = f1_score(y2_test, y_pred_thresh)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = thresh\n",
    "    \n",
    "    print(f\"Best F1: {best_f1:.3f} at threshold {best_thresh:.2f}\")\n",
    "    # Final prediction using best threshold\n",
    "    y2_pred_final = (y2_scores >= best_thresh).astype(int)\n",
    "\n",
    "\n",
    "    # --- Feature Importances ---\n",
    "    best_rf = rand_search.best_estimator_\n",
    "    feature_importances = pd.Series(best_rf.feature_importances_, index=feature_names)\n",
    "\n",
    "    grouped_importances_sum = feature_importances.groupby(get_prefix).sum()\n",
    "    grouped_importances_max = feature_importances.groupby(get_prefix).max()\n",
    "\n",
    "    if len(feature_names) > 10:\n",
    "        feature_importances.sort_values(ascending=False).head(50).plot.bar(figsize=(15, 5))\n",
    "        plt.savefig(f\"figs/classification/fi-{note}.pdf\", bbox_inches='tight')\n",
    "        plt.show()\n",
    "        grouped_importances_sum.sort_values(ascending=False).plot.bar(figsize=(15, 5), title=\"Grouped Feature Importances (sum)\")\n",
    "        plt.show()\n",
    "        grouped_importances_max.sort_values(ascending=False).plot.bar(figsize=(15, 5), title=\"Grouped Feature Importances (max)\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        feature_importances.sort_values(ascending=True).plot.barh(figsize=(5, 5))\n",
    "        plt.savefig(f\"figs/classification/fi-{note}.pdf\", bbox_inches='tight')\n",
    "        plt.show()\n",
    "        grouped_importances_sum.sort_values(ascending=False).plot.barh(figsize=(5, 5), title=\"Grouped Feature Importances (sum)\")\n",
    "        plt.show()\n",
    "        grouped_importances_max.sort_values(ascending=False).plot.barh(figsize=(5, 5), title=\"Grouped Feature Importances (max)\")\n",
    "        plt.show()\n",
    "\n",
    "    if shap_set == \"test\":\n",
    "        X2_train_or_test_scaled_df = X2_test_scaled_df\n",
    "        note = \"testset-\" + note\n",
    "\n",
    "    elif shap_set == \"train\":\n",
    "        X2_train_or_test_scaled_df = X2_train_scaled_df\n",
    "        note = \"trainset-\" + note\n",
    "\n",
    "    else:\n",
    "        return rand_search\n",
    "\n",
    "    # --- SHAP Analysis with new API and beeswarm plots ---\n",
    "    explainer = shap.TreeExplainer(best_rf)\n",
    "    shap_values = np.array(explainer.shap_values(X2_train_or_test_scaled_df))\n",
    "    #print(shap_values.shape) # This returns a shap.Explanation object\n",
    "\n",
    "    #shap_values_class_0 = shap_values[:, :, 0]  # SHAP values for class 0\n",
    "    #shap_values_class_1 = shap_values[:, :, 1]  # SHAP values for class 1\n",
    "    #shap_values_class_2 = shap_values[:, :, 2]  # SHAP values for class 2\n",
    "\n",
    "    # If multiclass: shap_values[i] contains class-specific contributions\n",
    "    for i in range(shap_values.shape[2]):  # Loop over number of classes\n",
    "        print(f\"Generating SHAP beeswarm plot for class {i}\")\n",
    "        plt.figure()\n",
    "        shap.summary_plot(shap_values[:, :, i], X2_train_or_test_scaled_df, show=False)\n",
    "        plt.title(\"Class \" + str(i) + \":\\nUsers who watched \" + class_names[i] + \" of the video duration\")\n",
    "        plt.savefig(f\"figs/classification/shap-{note}-class-{i}.pdf\", bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    return rand_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57231d73-97ae-4442-8e98-478b7b49f533",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7842ed0-e4bb-48f0-b17d-eb9e32161926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"data/data_survey&trace&interests_dummy.csv\", index_col=0)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b23042-227a-4739-8f7f-e79543524476",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# EXPLORATORY ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4bb30-3955-4843-8a83-053975029da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dim_fig((12,14,14))\n",
    "plot_hist_count_perc (df_all, col='percentage_watched', title='Histogram of the Percentage of Video Watched')\n",
    "plot_hist_count_perc (df_all, col='watched_until_end', title='Histogram of the Video Watched until the end vs. not')\n",
    "set_dim_fig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25dc86-8fed-4cfb-b731-fca9e8ccfbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07adad83-3cc3-4e56-99a4-2c0ed238751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p_watch = pd.DataFrame(df_all[[\"watched_until_end\", \"tt_account\"]].groupby(\"tt_account\").sum())\n",
    "df_p_watch[\"watched\"] = pd.DataFrame(df_all[[\"watched_until_end\", \"tt_account\"]].groupby(\"tt_account\").count())\n",
    "df_p_watch.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98af105e-0a6f-42d5-9221-85f51d81157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cdf(df_p_watch, cols=[\"watched_until_end\", \"watched\"], color=None, \n",
    "         xlab=\"Number of videos watched\", ylab=\"Proportion of users\", \n",
    "         note=\"playlist-final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d85a2-0688-452d-b1ba-32821063d35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v_watch = pd.DataFrame(df_all[[\"watched_until_end\", \"video_id_playlist_final\"]].groupby(\"video_id_playlist_final\").sum())\n",
    "df_v_watch[\"watched\"] = pd.DataFrame(df_all[[\"watched_until_end\", \"video_id_playlist_final\"]].groupby(\"video_id_playlist_final\").count())\n",
    "df_v_watch.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bdb3d3-a080-4a74-a49d-8dda09e6a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cdf(df_v_watch, cols=[\"watched_until_end\", \"watched\"], color=None, \n",
    "         xlab=\"Number of users\", ylab=\"Proportion of videos\", \n",
    "         note=\"playlist-final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b83078-ae24-4ac9-9183-5f7da002623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = df_all[[\"video_id_playlist_final\", \"video_duration\"]].drop_duplicates().set_index(\"video_id_playlist_final\")\n",
    "df_v.index.name = None\n",
    "df_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f976784b-1543-4e48-8c07-c6027d2d61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cdf(df_v, cols=[\"video_duration\"], color=\"green\",\n",
    "         xlab=\"Video duration (seconds)\", ylab=\"Proportion of videos\", \n",
    "         note=\"playlist-final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd02612-5096-4ae0-8957-702fc525a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = df_v.merge(df_v_watch, left_index=True, right_index=True) #getting the number of participants who watched & until the end each video\n",
    "df_v[\"%watched_until_end\"] = df_v_watch[\"watched_until_end\"] / df_v_watch[\"watched\"] * 100\n",
    "df_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b080dcbb-7ccd-4829-a956-da414115166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v.plot.scatter(\"video_duration\", \"%watched_until_end\") #percentage of users who watched the video until the end\n",
    "#plt.title(\"Correlation between video duration \\nand the percentage of participants who \\nwatched the video until the end: \" + str(round(df_v_watch[\"video_duration\"].corr(df_v_watch[\"%watched_until_end\"]), 2)))\n",
    "plt.xlabel(\"Video duration (seconds)\")\n",
    "plt.ylabel(\"Percentage of participants \\n who watched the video \\n until the end\")\n",
    "plt.text(300, 70, \"Correlation:\" + str(round(df_v[\"video_duration\"].corr(df_v[\"%watched_until_end\"]), 2)), size=14)\n",
    "plt.gca().set_yticklabels([f'{x/100:.0%}' for x in plt.gca().get_yticks()]) \n",
    "plt.savefig(f\"figs/scatter-video-duration-perc_watched.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7dca8-02f1-4a97-91c5-79d95139abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.plot.scatter(\"video_duration\", \"percentage_watched\") #percentage of the video watched\n",
    "plt.xlabel(\"Video duration (seconds)\")\n",
    "plt.ylabel(\"Percentage of the \\n video watched\")\n",
    "plt.text(300, 90, \"Correlation = \" + str(round(df_all[\"video_duration\"].corr(df_all[\"percentage_watched\"]), 2)), size=14)\n",
    "plt.gca().set_yticklabels([f'{x/100:.0%}' for x in plt.gca().get_yticks()]) \n",
    "plt.savefig(f\"figs/scatter-video-duration-perc_watched-video.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d2bcc-2840-4658-9b75-22793ecd9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dim_fig((14,20,20))\n",
    "plot_bar(df_stats=df_v, cols=[\"video_duration\"], bar=\"v\",\n",
    "         xlab=\"Video ID\", ylab=\"Video duration (seconds)\", note=\"order\", figsize=(5,20))\n",
    "set_dim_fig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9090427-47ee-49c4-b636-f0087d884941",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dim_fig((14,20,20))\n",
    "plot_bar(df_stats=df_v, cols=[\"%watched_until_end\"], bar=\"v\", percentage=True,\n",
    "         xlab=\"Video ID\", ylab=\"Percentage of participants who \\n watched the video until the end\", note=\"order\", figsize=(5,20))\n",
    "set_dim_fig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f355fd04-41e2-4d83-a7bb-b18a03e2baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[[\"SEQUENTIAL_ID\", \"tt_account\"]].drop_duplicates().sort_values(by=\"SEQUENTIAL_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25bad4e-6700-448a-9ba5-4e89ffae2297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heatmap_aux = df_all[[\"video_id_playlist_final\", \"tt_account\", \"percentage_watched\"]]\n",
    "df_heatmap = pd.pivot_table(df_heatmap_aux, values=\"percentage_watched\", index=\"tt_account\",\n",
    "                       columns=\"video_id_playlist_final\")\n",
    "df_heatmap.fillna(-1, inplace=True)\n",
    "df_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6859fe-d614-4320-b772-76336a8f5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heatmap.reset_index(inplace=True, drop=True)\n",
    "# reset the index and add 1 to each value\n",
    "df_heatmap.index = df_heatmap.index + 1\n",
    "df_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8fdf19-850d-4eff-af84-275c7e126806",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dim_fig((14,20,20))\n",
    "\n",
    "my_cmap = copy(plt.cm.RdBu_r)\n",
    "my_cmap.set_under(\"gray\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "sns.heatmap(\n",
    "    df_heatmap, \n",
    "    cmap=my_cmap, \n",
    "    vmin=0, \n",
    "    vmax=100, \n",
    "    ax=ax,\n",
    "    cbar_kws=dict(\n",
    "        label='Percentage of the video watched',\n",
    "        use_gridspec=False,\n",
    "        location=\"right\",\n",
    "        pad=0.008\n",
    "    )\n",
    ")\n",
    "plt.xlabel(\"Video ID\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.ylabel(\"Participant ID\")\n",
    "\n",
    "# Format colorbar ticks as percentages\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.0f%%'))\n",
    "\n",
    "# Manually adjust colorbar width only\n",
    "#pos = cbar.ax.get_position()\n",
    "#cbar.ax.set_position([pos.x0, pos.y0, 0.01, pos.height])  # Width only\n",
    "\n",
    "plt.savefig(f\"figs/heatmap.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "set_dim_fig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f805ea1d-ada6-404d-83b5-b2f1579028b9",
   "metadata": {},
   "source": [
    "## Comparison with TikTok statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6504c-fd56-4806-a3e8-9aea9af9dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiktok_stats = pd.read_csv(\"data/Prolific_groups.csv\")\n",
    "df_tiktok_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fef759-f7eb-4c71-a702-4bd34ed50072",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prolific_groups = df_all[[\"prolific_group\", \"tt_account\"]].drop_duplicates().groupby(by=\"prolific_group\").count()\n",
    "df_prolific_groups[\"Participants\"] = df_prolific_groups[\"tt_account\"]/df_prolific_groups[\"tt_account\"].sum()*100\n",
    "df_prolific_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f34acbb-0a1f-4481-a1c6-88f67721c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_tt = list(df_tiktok_stats[\"%Female\"][:5]) + list(df_tiktok_stats[\"%Male\"][:5])\n",
    "df_prolific_groups[\"TikTok statistics 2023\"] = stats_tt\n",
    "df_prolific_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e245e-1d46-4205-a8ce-a526570540dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total participants: \", df_prolific_groups[\"tt_account\"].sum())\n",
    "plot_bar(df_stats=df_prolific_groups, cols=[\"Participants\",\"TikTok statistics 2023\"], bar=\"v\", stacked=False, \n",
    "         xlab=\"Sex and age group\", ylab=\"Percentage of users\", figsize=(5,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1686b70e-2678-45fc-9c13-d3edc9ec8372",
   "metadata": {},
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c68d37-0f51-46ff-b0cd-10fa6aac728f",
   "metadata": {},
   "source": [
    "# TikTok Experiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f0377-53c8-4940-99e2-fe94b9f0ca3e",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7cb016-a23c-4080-b1d4-a43140c95727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the SEQUENTIAL_ID column\n",
    "one_hot_user_df = pd.get_dummies(df_all['SEQUENTIAL_ID'], prefix='User ID')\n",
    "\n",
    "df_all_rf = df_all.drop(columns=['Date', 'Link','video_id','in_playlist','in_playlist_final','video_id_playlist', 'watching_time',\n",
    "                                 'percentage_watched_float','percentage_watched', 'prolific_group','SEQUENTIAL_ID',\n",
    "                                 'tt_account','like','comment', 'common_interests','all_interests', 'num_topics_video', \n",
    "                                 'jacc_original_interests', 'video_saves', 'watched_6s+'])\n",
    "\n",
    "df_all_rf.rename(columns={\"jacc_interests\": \"Interest Similarity\", \n",
    "                         'video_id_playlist_final': \"Video ID playlist\",\n",
    "                         'video_duration': \"Video duration\",\n",
    "                         'video_likes': \"Video num. likes\",\n",
    "                         'video_shares': \"Video num. shares\",\n",
    "                         'video_comments': \"Video num. comments\",\n",
    "                         'video_plays': \"Video num. plays\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3832c9-5e62-4e39-bfcd-50da7d0b4c81",
   "metadata": {},
   "source": [
    "## Random model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac83ec-ff31-4cc5-8249-e686f21c71c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_model(df_all_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b5439-6537-4839-82f3-a35fa780da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all_rf.drop(columns=[\"watched_until_end\"]).shape, df_all_rf.drop(columns=[\"watched_until_end\"]).drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ecce6c-d045-42ba-b735-575e3867793b",
   "metadata": {},
   "source": [
    "## Model all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5357d5-7070-4cce-bbfa-a4269167334d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_rf = [c for c in df_all_rf.columns.tolist() if c != 'watched_until_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff93be5-e401-410d-8000-e5ed935c0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_all = df_all_rf[columns_rf]\n",
    "y2_all = df_all_rf[\"watched_until_end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfedecb8-f728-45b2-ad03-638370fcf22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X2_train_all, X2_test_all, y2_train_all, y2_test_all = train_test_split(X2_all, y2_all, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa2b89-6c2f-490c-a0fd-fe9f16f8977b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_dim_fig((12,14,20))\n",
    "rand_search_all = randomforest_tiktok(X2_train_all, X2_test_all, y2_train_all, y2_test_all, note=\"model_all\")\n",
    "#rand_search_all = randomforest_tiktok(X2_train_all, X2_test_all, y2_train_all, y2_test_all, shap_set=\"train\", note=\"model_all\")\n",
    "#rand_search_all = randomforest_tiktok(X2_train_all, X2_test_all, y2_train_all, y2_test_all, shap_set=\"test\", note=\"model_all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5926f9-f5e1-4f76-aef8-7f363b7ca558",
   "metadata": {},
   "source": [
    "## Model video metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbfa920-4bfb-4e7c-9122-39bc119060b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_meta = [\"Video duration\", \n",
    "                \"Video ID playlist\", \n",
    "                \"Video num. plays\", \n",
    "                \"Video num. comments\", \n",
    "                \"Video num. shares\", \n",
    "                \"Video num. likes\"]\n",
    "\n",
    "df_meta_rf = df_all_rf[columns_meta + [\"watched_until_end\"]]\n",
    "df_meta_rf = df_meta_rf.merge(one_hot_user_df, left_index=True, right_index=True) # adding one hot encoding user ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee3c27-4a5a-471d-a14a-5ee86f996160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4739bf-8752-44ad-81d8-d1ec44842210",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_meta = df_meta_rf.drop(columns=['watched_until_end'])\n",
    "y2_meta = df_meta_rf[\"watched_until_end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X2_train_meta, X2_test_meta, y2_train_meta, y2_test_meta = train_test_split(X2_meta, y2_meta, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695e6e2-6fb2-44a5-a6b6-78449b22e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dim_fig((20,20,20))\n",
    "rand_search_meta = randomforest_tiktok(X2_train_meta, X2_test_meta, y2_train_meta, y2_test_meta, note=\"model_meta\")\n",
    "#rand_search_meta = randomforest_tiktok(X2_train_meta, X2_test_meta, y2_train_meta, y2_test_meta, shap_set=\"train\", note=\"model_meta\")\n",
    "#rand_search_meta = randomforest_tiktok(X2_train_meta, X2_test_meta, y2_train_meta, y2_test_meta, shap_set=\"test\", note=\"model_meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d343ed0e-767d-4577-b267-37fcef173d8d",
   "metadata": {},
   "source": [
    "# TikTok real world data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff6f016-5ae5-47a0-8ec5-cd499f72be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_world = pd.read_csv(\"data/data_donation_for_classification_allvideosNorthCentral America.csv\", index_col=0)\n",
    "df_real_world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87159ed-ffdb-40da-b199-c3f32545794f",
   "metadata": {},
   "source": [
    "## Selecting only the first K videos watched by each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c6102f-da5d-4cdd-81b2-375f9d27df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=104\n",
    "df_real_world = df_real_world[df_real_world[\"video_id_playlist\"] <= K]\n",
    "df_real_world.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0642cd-8442-45a1-9fe6-74cb3f070fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the SEQUENTIAL_ID column\n",
    "one_hot_user_real_df = pd.get_dummies(df_real_world['email_md5'], prefix='User ID')\n",
    "\n",
    "df_real_world = df_real_world.drop(columns=['percentage_watched', 'liked', 'watched_6s+'])\n",
    "\n",
    "df_real_world.rename(columns={'video_id_playlist': \"Video ID playlist\", \n",
    "                              'video_duration': \"Video duration\",\n",
    "                              'video_digg_count': \"Video num. likes\",\n",
    "                              'video_share_count': \"Video num. shares\",\n",
    "                              'video_comment_count': \"Video num. comments\",\n",
    "                              'video_play_count': \"Video num. plays\"}, inplace=True)\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e182f64-44ab-4016-b370-0d47759b3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_world = df_real_world[columns_meta + [\"watched_until_end\"]]\n",
    "df_real_world = df_real_world.merge(one_hot_user_real_df, left_index=True, right_index=True) # adding one hot encoding user ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b80b11-cbff-43b5-8e5f-9677cee9b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_real_world_meta = df_real_world.drop(columns=['watched_until_end'])\n",
    "y2_real_world = df_real_world[\"watched_until_end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62d0a9-23f8-482f-969a-7b7eefd68dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X2_real_world_meta.shape, X2_real_world_meta.drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac02ddbc-d195-4bf2-bf17-0f62d5be07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X2_train_real_world_meta, X2_test_real_world_meta, y2_train_real_world, y2_test_real_world = train_test_split(X2_real_world_meta, y2_real_world, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ee6984-7a9b-4b89-8d60-df8766674dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dim_fig((20,20,20))\n",
    "rand_search_real_world_meta = randomforest_tiktok(X2_train_real_world_meta, X2_test_real_world_meta, y2_train_real_world, y2_test_real_world, note=\"model_real_world_meta\")\n",
    "#rand_search_real_world_meta = randomforest_tiktok(X2_train_real_world_meta, X2_test_real_world_meta, y2_train_real_world, y2_test_real_world, shap_set=\"train\", note=\"model_real_world_meta\")\n",
    "#rand_search_real_world_meta = randomforest_tiktok(X2_train_real_world_meta, X2_test_real_world_meta, y2_train_real_world, y2_test_real_world, shap_set=\"test\", note=\"model_real_world_meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddde67d-74aa-4cad-a93b-09075ab8176f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3803fa46-71dc-415c-834e-20d0d3429da1",
   "metadata": {},
   "source": [
    "# Summary Data for Classification: Real World vs. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85634975-c818-4f30-9677-68510af60dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"******** Real World Data ********\")\n",
    "print(\"Users: 108 \\nVideos: 6091\")\n",
    "print(\"Classification matrix:\", X2_real_world_meta.shape)\n",
    "print(y2_real_world.value_counts(), y2_real_world.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35fa999-4e83-47d9-848f-91c95008e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"******** Experiment data ********\")\n",
    "print(\"Users: 80 \\nVideos: 105\")\n",
    "print(\"Classification matrix (all features):\", X2_all.shape)\n",
    "print(\"Classification matrix (video metadata):\", X2_meta.shape)\n",
    "print(y2_meta.value_counts(), y2_meta.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a09e105-569e-45c0-bc19-68c1fb3bfc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_rf[[\"Video ID playlist\", \"watched_until_end\", \"Video duration\"]].groupby(by=[\"Video ID playlist\", \"watched_until_end\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a6410-dc1a-432f-9488-84ba90e0242e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
